---
title: Overview
description: Destination config Description
sidebar_position: 3
---

# Supported Destinations

OLake replicates data to multiple destinations to cater to a variety of deployment scenarios. 

Whether you're storing data locally for quick access or using cloud storage services like S3 for scalability, our system is designed to integrate seamlessly. 

We are also working on adding support for Iceberg to facilitate advanced analytics and data lake management.

| Destination       | Supported | Docs | 
|-------------------|-----------| ---- | 
| <img src="/img/logo/local.png"  className="mt-3"  height={20} /> Local Filesystem  | Yes       | [Link](./local) |
| <img src="/img/logo/s3.png"  className="mt-3"  height={20} /> S3                | Yes       | [Link](./s3/overview) |
| <img src="/img/logo/iceberg.png"  className="mt-3"  height={20} /> Iceberg           | Yes       | [Link](./iceberg/overview) |

Visit [OLake roadmap](../roadmap) for more information.

Before proceeding with either configuration, please ensure you have completed the [getting started](../getting-started/overview) instructions. For more background details, refer to the [README section](https://github.com/datazip-inc/olake/blob/master/README.md).

##  Data Partitioning

While not directly configured in `destination.json`, data partitioning is an important aspect of how your data is organized when written to storage. For more details on partitioning strategies, please refer to: 

- The [AWS S3 partitioning documentation](./s3/partitioning).
- The [Apache Iceberg data partitioning documentation](./iceberg/partitioning).


## Schema Evolution and Data Type Mapping
Schema evolution is a critical feature that allows you to modify the structure of your data over time. OLake supports schema evolution, enabling you to add, remove, or change fields in your data schema without losing existing data.
For more information on schema evolution and data type mapping, please refer to the following sections:
- [Schema Evolution](../features/schema)

## OLake System Columns (Iceberg storage layer)

| Column name | Iceberg data type* | Description |
|-------------|-------------------|-------------|
| **`data`** | `string` (materialised as a single **JSON** string in Parquet) | Snapshot of the source row at the time of the event, if used with normalization turned off.<br/>• Contains every source-table column as key → value pairs.<br/>• If the pipeline is running in *“normalised”* mode, individual keys may also appear as first-class columns in the Iceberg table. |
| **`_olake_id`** | `string` | Deterministic, content-addressable identifier for the record.<br/>Computed as a hash of the source table’s primary-key value(s). |
| **`_olake_timestamp`** | `timestamp` (stored as `INT64` epoch µs in Parquet) | Ingestion timestamp generated by OLake **at write time** (always UTC). Useful for auditing, incremental reads, and late-arrival handling. |
| **`_op_type`** | `string` (one-char code) | Change-event type emitted by the connector: <br/>`r` = historical back-fill/read `c` = insert/create `u` = update `d` = delete. |
| **`_cdc_timestamp`** | `timestamp` (stored as `INT64` epoch µs in Parquet) | Exact commit timestamp captured from the *source* database’s change-data-capture stream (e.g., WAL, binlog). Represents when the mutation happened on the upstream system, independent of when OLake processed it. Defaults to a epoch start time if CDC operation not performed.|

:::note
If any columns from the source database does not have value in it, it won't get created in the iceberg tables.
:::

If you have any further questions or need additional support, please refer to the [getting started](../getting-started/overview) section or the [OLake README](https://github.com/datazip-inc/olake/blob/master/README.md).
