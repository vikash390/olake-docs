---
title: Create Jobs
description: OLake Create Jobs
sidebar_position: 2
---

## 1. Create Jobs

Jobs are a way to run OLake processes like sync, discover, and others in a controlled manner. They allow you to schedule and manage these processes efficiently. You can create a job by:

1. Clicking on the "Jobs" tab in the OLake UI.
2. and then clicking on the "Create Job" button.

![olake-job-1](/img/docs/jobs/olake-job-1.png)

## 2. Configure the Source
Now, you need to setup your source configuration: 
- [Postgres](../connectors/postgres/overview) 
- [MySQL](../connectors/mysql/overview) 
- [MongoDB](../connectors/mongodb/overview). 
    
Enter the source configuration details in the provided fields. 

You can refer to the [Source documentation](../connectors/overview) for that particular source for more information on how to set up your source configuration or the required documentation for your specific source type will be displayed at the right side of the screen.

![olake-job-2](/img/docs/jobs/olake-job-2.png)

Click on the "Next" button to proceed to the destination configuration.

OLake will test the source connection and display the results. If the connection is successful, you will see a success message. If there are any issues, OLake will provide error messages to help you troubleshoot.

![olake-job-3](/img/docs/jobs/olake-job-3.png)

:::info
You can either **create a new source configuration** or select an **existing source** by toggling the radio button at top. If you choose to create a new source, you will need to provide the necessary details for the source configuration.
:::

## 3. Configure the Destination
Now you need to setup your destination configuration. 

Enter the destination configuration details in the provided fields. You can pick from:

### Destination: 
- [Apache Iceberg](../writers/iceberg/overview) 
- [AWS S3](../writers/s3/overview)

### Catalog (for Apache Iceberg as destination):

- [AWS Glue](../writers/iceberg/catalog/glue)
- [JDBC](../writers/iceberg/catalog/jdbc)
- [REST](../writers/iceberg/catalog/rest)
- [Hive](../writers/iceberg/catalog/hive)

![olake-job-4](/img/docs/jobs/olake-job-4.png)

You can refer to the [Destination documentation](../writers/overview) for that particular destination for more information on how to set up your destination configuration or the required documentation for your specific destination type will be displayed at the right side of the screen.

OLake will test the destination connection and display the results. If the connection is successful, you will see a success message. If there are any issues, OLake will provide error messages to help you troubleshoot.

:::info
You can either **create a new destination** configuration or select an **existing destination** by toggling the radio button at top. If you choose to create a new source, you will need to provide the necessary details for the source configuration.
:::

## 4. Stream Selection

Select the stream you want to use for the job. You can choose from the available streams you want to sync data from. 

If you want to sync all streams, you can select the "All Tables" option.

![olake-job-5](/img/docs/jobs/olake-job-5.png)

Other stream selection options include:
- **All tables:** Selects all tables from the source.
- **Change Data Capture (CDC):** Selects tables that have CDC enabled.
- **Full Refresh**: Selects tables that are not part of CDC.
- **Selected Tables**: Allows you to select specific tables from the source.
- **Not Selected Tables**: Shows you the tables that are not part of the selected tables.

![olake-job-6](/img/docs/jobs/olake-job-6.png)

For each stream, you have the follow configurations options:

Under Config, you have:
- **Sync Mode**: Choose between `Full Refresh` or `Change Data Capture (CDC)`.
- **Enable backfill**: If you want to backfill the data, you can enable this option. This will sync all historical data from the source to the destination.
- **Normalize**: If you want to normalize the data, you can enable this option. This will convert the data into a normalized format (Level 1 flattening) before syncing it to the destination.

![olake-job-7](/img/docs/jobs/olake-job-7.png)

Under Schema, you can see all the column types and their data types. You can also see the primary key and unique key columns for the stream that will later help you to define `partition_regex` for the destination table.

![olake-job-8](/img/docs/jobs/olake-job-8.png)

Under Partitioning, you can define how the data should be partitioned. There are 2 types of data partitioning depending upon your destination type.

1. For Data Partitioning in the **Apache Iceberg table**, follow the [Iceberg Partitioning guide](../writers/iceberg/partitioning) for detailed information.
2. For Data Partitioning in **AWS S3**, follow the [AWS S3 Partitioning guide](../writers/s3/partitioning) for detailed information.

![olake-job-9](/img/docs/jobs/olake-job-9.png)

## 5. Job Configuration

Under the Job Configuration section, you can set the following options:
1. **Job Name**: Enter a name for your job.
2. **Replication Frequency**: Choose how often you want the job to run. You can select from the available options or set a custom frequency.
3. **Replication Frequency Value**: Select the value for the replication frequency. This will determine how often the job will run:
    - **Minutes**: Runs every minute.
    - **Hourly**: Runs every hour.
    - **Days**: Runs every day.
    - **Weeks**: Runs every week.
    - **Months**: Runs every week.
    - **Years**: Runs every week.

![olake-job-10](/img/docs/jobs/olake-job-10.png)

Once the job configuration is complete, click on the "Create Job" button to create the job.

:::info
You can also set the job to run immediately after creation by clicking on the `Sync Now` button. This will start the job immediately and sync the data from the source to the destination.

![olake-job-11](/img/docs/jobs/olake-job-11.png)
:::
